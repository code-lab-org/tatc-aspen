{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518a70ab-1ac3-44df-a05e-f2625865384f",
   "metadata": {},
   "source": [
    "# TAT-C for Scalable Services Report\n",
    "PI: Paul T. Grogan paul.grogan@asu.edu\n",
    "\n",
    "Contributors: Josue Tapia josue.tapia@asu.edu and Suvan Kumar skuma208@asu.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253d428-6304-4e6d-8a86-cfb34a7440f7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This report provides an overview of the Tradespace Analysis Tool for Constellations (TAT-C) architecture for scalable services to support trade space exploration and assesment of hypothetical mission designs autonomously and to interface with the NOAA's ASPEN trade space evaluation tool. The new architecture leverages the Celery python library to distribute and execute tasks in parallel, reducing the simulation runtime per mission assesment. This work has been performed under the project \"OSSE / Trade Space Capability for NOAA's Future Mission Design.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba075e51-d890-480d-8500-b0409f9e8e40",
   "metadata": {},
   "source": [
    "# Background\n",
    "## TAT-C Capabilities\n",
    "The Tradespace Analysis Tool for Constellations (TAT-C) is an open-source Python software package for early-stage mission modeling, simulation, and analysis for Earth-observing satellite constellations. It was developed with support from the NASA Advanced Information Systems Technology (AIST) program grants NNX17AE06G, 80NSSC17K0586, 80NSSC20K1118, and 80NSSC21K1515. This project uses TAT-C version 3 which is the third major revision to the tool.\n",
    "\n",
    "TAT-C simulates the orbital motion and observability conditions of satellite-based instruments and produces data such as orbit track, ground track (projected sensor area), and observation records. Analysis methods compute key mission performance metrics such as revisit time (time between subsequent observations of a fixed point) and data latency (time from observation of a fixed point until the first available downlink opportunity) to support trade studies.\n",
    "\n",
    "The overall objective of this project is to use TAT-C as a pre-processor for the Advanced Systems Performance Evaluation tool for NOAA (ASPEN) Sensor Constellation/Performance (SCP) table. SCP columns that can be informed by TAT-C analysis include (descriptions from ASPEN-91 definition tables):\n",
    "\n",
    "*  Temporal Refresh: \"Time between obsevations at a location, i.e., time to obseve the geographic coverage region D.\"\n",
    "*  Data Latency: \"Time from 'image taken' to full relay of data to a ground station.\" (Note: TAT-C does not consider processing time as a part of data latency; in other words, an additional factor must be added to the TAT-C results.)\n",
    "  \n",
    "TAT-C models instrument observability constraints rather geophysical variables. Instruments selected for this report consist of infrared and microwave sounders and visual/infrared imagers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747303b7-f23c-47f1-9105-e19a237d247d",
   "metadata": {},
   "source": [
    "# TAT-C Configuration\n",
    "This report uses TAT-C version 3.1.3 which is currently in development on the main branch of GitHub. Technical documentation is available at ReadTheDocs.\n",
    "\n",
    "TAT-C can be installed from PyPI via the terminal/shell command `pip install tatc`\n",
    "\n",
    "Alternatively to install TAT-C, clone the repository:\n",
    "\n",
    "    git clone https://github.com/code-lab-org/tatc\n",
    "and install the dependencies into a new environment (tatc_env) using conda:\n",
    "\n",
    "    conda env create -f environment.yml\n",
    "(note: dependency resolution can take upwards of 10 minutes). Activate the new environment when complete:\n",
    "\n",
    "    conda activate tatc_env\n",
    "and register the TAT-C library in \"editable\" mode (enables source changes, if desired):\n",
    "\n",
    "    pip install -e .\n",
    "This report also requires the following additional dependencies for parallel processing and interactive features of a Jupyter notebook:\n",
    "\n",
    "    conda install ipython joblib pandarallel -c conda-forge\n",
    "and a world country-level shapefile `ne_110m_admin_0_countries.zip` available from NaturalEarth (Select \"Download countries\" and save the .zip file in the same directory as this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f19d8-15be-4647-a460-b27d67b53e39",
   "metadata": {},
   "source": [
    "#  Simulation Runtime Limitation\n",
    "The TAT-C is a long runtime simulation analysis tool due to arduos tasks. As a result, TAT-C can be used for narrow trade space analysis, which evaluates the performance of a few mission architectures. This limitation hinders mission designs that could maximize system performance while minimizing costs.\n",
    "\n",
    "This leads to the need for scalable approaches that reduce the TAT-C's simulation runtime. The following section describes a scalable architecture that relies on the Python Celery library, which computes tasks in parallel and asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e6b7cc-c08f-4588-8dc6-aa1d8fbd8046",
   "metadata": {},
   "source": [
    "# Scalable Architecture\n",
    "\n",
    "The image bellow represents the scalabe architecture developed in this report. The architecture has three main components: the TAT-C application, the backend and message broker, and the machine workers. The TAT-C application splits big tasks into small ones. The celery framework supports a message broker (Rabbit MQ) and a database (Redis). The message broker places tasks in a queuing system and distributes them to machine workers, which execute tasks. As workers complete tasks, they store the results in the Redis database. Once all tasks are complete, TAT-C requests the results to the Redis database and aggregates the results to compute coverage analysis. The following subsections address each of these main components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a98292-7fe1-43c4-a42d-54a2541372dd",
   "metadata": {},
   "source": [
    "<img src='./images/Scalable_Architecture.png' align='center'/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31ab8eb4-879f-46e7-a13d-2ac88fc97e1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## TAT-C Application\n",
    "\n",
    "This subsection shows how the TAT-C application breaks down a big task, such as the refresh analysis for a mission architecture, into small and independent tasks that can be executed in parallel. Additionally, the subsection describes the Celery workflows used in the architecture.  \n",
    "\n",
    "### Celery Workflows\n",
    "\n",
    "Celery processes and handles data flows as shown in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76eae29-0ee6-41fb-9196-ab12be9f45c2",
   "metadata": {},
   "source": [
    "<img src='./images/celery_workflows.png' width='600' align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df365e2-7c7e-40e7-96b4-4f107b15df87",
   "metadata": {},
   "source": [
    "* The chain workflow executes tasks in sequence, one after another. The results of each tasks are passed to the following task as the first argument. The output is a result value processed by the last task.\n",
    "* The group workflow executes a set of tasks in parallel. The output is a list of results of each task.\n",
    "* The chord workflow executes a task after a set of tasks computed in parallel. The list of results from the the group task is passed to the last task as the first argument. The output is a result processed by the last task.\n",
    "\n",
    "Note that the data transferred from one task to another needs to be serialized. Since tatc outputs geodataframes with coverage statistics, we need to serialize the geodataframes to pass results from one taks to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166ac43-4fc2-4cdf-9699-4c0b20f13d49",
   "metadata": {},
   "source": [
    "### Grouping Small Tasks for Scalable Services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90006e5-67f3-40a7-a0e0-685c20da4927",
   "metadata": {},
   "source": [
    "There are several ways to structure functions in tatc to provide coverage or data latency statistics using Celery's workflows. We determined that the following workflow offers a lower network latency. The diagram below shows the workflow to run revisit time/harmonic mean analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85870d85-7a1f-49f9-878a-4fa5b4279f34",
   "metadata": {},
   "source": [
    "<img src='./images/run_coverage_analysis.jpg' width='600' align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dddf2d9-d1c9-42a9-ae4b-2c530e575037",
   "metadata": {},
   "source": [
    "The `run_coverage_analysis_task` computes revist time statistics of a constellation over one target point in the grid. Each task of the group workflow is executed in parallel. Celery sends the group results as a list to the `merge_feature_collection` task, which merges a list of geodataframes into one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ffe15-fe39-4a25-b8da-a11e7dfb1543",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##  Message Broker and Backend\n",
    "\n",
    "This project utilzes the Rabbit MQ message broker and Redis backend hosted in Amazon Web Servicies (AWS).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86dd23a-8e95-4cb4-b41a-9f900b542fb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## IP Data Transfer\n",
    "\n",
    "The communication between message broker, backend, tatc appication, and machine workers is done by using the https protocol. The protocol encrypts the messages. The advantage of using the https protocol in the network is that it can connect workers that are distributed globally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba7884-023f-43f0-9167-fdacd8076be5",
   "metadata": {},
   "source": [
    "## Machine Workers\n",
    "We built a docker image that builds a worker machine container. This container carries all dependencies needed to run a coverage analys using tatc. The image is publicly available in Docker Hub (codelaborg/tatc_aspen_pworker:latest). Alternatively, the image file is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619396d1-209c-4836-b6d6-de81cec4f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block defines the TAT-C runtime container using the appropriate\n",
    "# base Python environment.\n",
    "\n",
    "FROM python:3.10 AS tatc_runtime\n",
    "\n",
    "WORKDIR /var/tatc\n",
    "COPY pyproject.toml ./\n",
    "COPY src src #copies the tatc library in this image\n",
    "RUN python -m pip install . --no-cache-dir\n",
    "\n",
    "# This block defines the TAT-C worker container. Using the TAT-C runtime\n",
    "# container, it installs and starts the worker application.\n",
    "\n",
    "FROM tatc_runtime AS tatc_worker\n",
    "\n",
    "WORKDIR /var/tatc\n",
    "RUN python -m pip install .[app] --no-cache-dir\n",
    "\n",
    "COPY tatc_app tatc_app\n",
    "COPY resources resources\n",
    "\n",
    "ENV TATC_BROKER\n",
    "ENV TATC_BACKEND\n",
    "\n",
    "CMD [\"celery\", \"-A\", \"tatc_app.aws_worker\", \"worker\", \"--uid=nobody\", \"--gid=nogroup\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d7e6a-ac0e-4b27-ad1a-3b4942c36370",
   "metadata": {},
   "source": [
    "This image file is located in the same directory as the tatc_app file, which contains the celery application initializer (the `aws_worker` file) as well as the coverage-task file. The celery application is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782c5ad-e5a3-4323-8627-43564a203248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from celery import Celery\n",
    "from skyfield.api import load\n",
    "import ssl\n",
    "\n",
    "app=Celery('tatc_app',\n",
    "           broker='TATC_BROKER_KEY',\n",
    "           broker_use_ssl= {\n",
    "               \"keyfile\": None,\n",
    "               \"certfile\":None,\n",
    "               \"ca_certs\": None,\n",
    "               \"cert_reqs\": ssl.CERT_NONE,\n",
    "               },\n",
    "           backend='TATC_BACKEND_KEY',\n",
    "           redis_backend_use_ssl={\n",
    "               \"ssl_keyfile\": None,\n",
    "               \"ssl_certfile\": None,\n",
    "               \"ssl_ca_certs\": None,\n",
    "               \"ssl_cert_reqs\": ssl.CERT_NONE,\n",
    "               },\n",
    "           include=['tatc_app.latency_tasks', 'tatc_app.coverage_tasks']\n",
    "    )\n",
    "\n",
    "load(\"de421.bsp\")\n",
    "if __name__=='__main__':\n",
    "    app.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb0a88-6c4e-4fb6-b4b9-0e9a72d9aa60",
   "metadata": {},
   "source": [
    "The following script shows coverage_tasks file, which contains the underlying tatc functions that support the `run_coverage_analysis_task` and the `merge_feature_collection_task`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91641ec-e5a6-4402-b014-fd2778f987fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import geopandas as gpd\n",
    "from geojson_pydantic import FeatureCollection\n",
    "import json\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from tatc.schemas.instrument import Instrument\n",
    "from tatc.schemas.point import Point\n",
    "from tatc.schemas.satellite import Satellite\n",
    "from tatc.analysis.coverage import (\n",
    "    collect_multi_observations,\n",
    "    aggregate_observations,\n",
    "    reduce_observations,\n",
    "    grid_observations,\n",
    ")\n",
    "\n",
    "#from .schemas import CoverageAnalysisResult\n",
    "from .aws_worker import app\n",
    "@app.task\n",
    "def run_coverage_analysis_task(\n",
    "    point: str, satellites: list, start: str, end: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Task to run coverage analysis.\n",
    "\n",
    "    Args:\n",
    "        point (str): JSON serialized :class:`tatc.schemas.Point` object.\n",
    "        satellites (list): List of JSON serialized :class:`tatc.schemas.Satellite` objects.\n",
    "        start (str): ISO 8601 serialized start time.\n",
    "        end (str): ISO 8601 serialized end time.\n",
    "\n",
    "    Returns:\n",
    "        str: GeoJSON serialized `FeatureCollection` containing coverage analysis.\n",
    "    \"\"\"\n",
    "    # call analysis function, parsing the serialized arguments\n",
    "    results = reduce_observations(\n",
    "        aggregate_observations(\n",
    "            collect_multi_observations(\n",
    "                Point.parse_raw(point),\n",
    "                [Satellite.parse_raw(satellite) for satellite in satellites],\n",
    "                datetime.fromisoformat(start),\n",
    "                datetime.fromisoformat(end),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # re-serialize constituent data\n",
    "    results[\"access\"] = results[\"access\"].apply(lambda t: t/timedelta(hours=1))\n",
    "    results[\"revisit\"] = results[\"revisit\"].apply(lambda t: t/timedelta(hours=1))\n",
    "    return results.to_json(show_bbox=False, drop_id=True)\n",
    "\n",
    "@app.task\n",
    "def merge_feature_collections_task(collections: list) -> str:\n",
    "    \"\"\"\n",
    "    Task to merge a list of feature collections into a single feature collection.\n",
    "\n",
    "    Args:\n",
    "        collections (list): GeoJSON serialized list of feature collections.\n",
    "\n",
    "    Results:\n",
    "        str: GeoJSON serialized feature collection.\n",
    "    \"\"\"\n",
    "    return FeatureCollection(\n",
    "        type=\"FeatureCollection\",\n",
    "        features=list(\n",
    "            chain(\n",
    "                *list(\n",
    "                    FeatureCollection.model_validate_json(collection).features\n",
    "                    for collection in collections\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "    ).model_dump_json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad5153ec-486e-4647-a4eb-9aaf54462fe0",
   "metadata": {},
   "source": [
    "#  Tradespace Analysis\n",
    "\n",
    "This section describes the script to perform a tradespace of 100 mission architectures using the scalable architecture. The 100 architecture are defined as a combination of multiple constellations:\n",
    "\n",
    "* Set of mid-inclination Orbit Alternatives: 32 alternatives with field of regard (FOR) [60,80], altitude [450, 550]Km, inclination [30, 60], walker ad star configurations, satellite and planes [(6,2), (12,4)].\n",
    "* Set of sunsynchronous orbit alternatives: three constellations with one satellite in one plane, two satellites in two planes, and three satellites in three planes. We generate a 96 architectures by combining each set the mid-inclination orbits and the sunsynchronous orbits.\n",
    "* One constellation with 60 satellites with small swath width (50 Km) and nadir-pointing sensors.\n",
    "* Three constellations with nadir-point satellites located in a sunsynchronous orbit and in three orbital planes.\n",
    "\n",
    "The `all_cons` variable in the script below contains all mission architectures in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727ffc4c-8c5f-4e5e-8bf2-74556b3575b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tatc.schemas import (CircularOrbit, Satellite,\n",
    "                          SunSynchronousOrbit, TwoLineElements,\n",
    "                          Instrument, WalkerConstellation\n",
    "                          )\n",
    "from tatc.utils import swath_width_to_field_of_regard\n",
    "######Circular and Mid-inclination Constellations  #####\n",
    "name:list=[]\n",
    "sats:list=[]\n",
    "inc:list=[]\n",
    "slew:list=[]\n",
    "pl:list=[]\n",
    "# list field of regard\n",
    "fors:list= [60, 80]\n",
    "# list of altitudes in Km\n",
    "altitudes: list= [450, 550]\n",
    "# list of inclinations\n",
    "inclination: list =[ 30, 60]\n",
    "cons_configuration:list=['star', 'delta']\n",
    "sat_pl:list=[(6, 2), (12, 4)]\n",
    "constellations:list=[]\n",
    "co=0\n",
    "for f in fors:\n",
    "    for alt in altitudes:\n",
    "        for incl in inclination:\n",
    "            for config in cons_configuration:\n",
    "                for rt in sat_pl:\n",
    "                    orb= CircularOrbit(type='circular',\n",
    "                                       altitude=alt*1000,\n",
    "                                       inclination=incl,\n",
    "\n",
    "                                       )\n",
    "                    inst=Instrument(name='ins1',\n",
    "                                    field_of_regard=f,\n",
    "                                    fixed_access_time=True)\n",
    "                    constellations.append(WalkerConstellation(name=f'Circular_{f}_alt_incl_con_{config}_satratio{rt[0]}/{rt[1]}',\n",
    "                                            orbit= orb.to_tle(),\n",
    "                                            instruments=[inst],\n",
    "                                            number_satellites=rt[0],\n",
    "                                            number_planes=rt[1],\n",
    "                                            configuration=config,).generate_members())\n",
    "\n",
    "                    sats.append(rt[0])\n",
    "                    pl.append(rt[1])\n",
    "                    inc.append(incl)\n",
    "                    slew.append(f)\n",
    "                    co+=1\n",
    "\n",
    "#######\n",
    "h_ref=800e3 #meters\n",
    "viirs = Instrument(\n",
    "    name=\"VIIRS\",\n",
    "    field_of_regard=swath_width_to_field_of_regard(h_ref, 3000e3),\n",
    "\n",
    "    fixed_access_time=True\n",
    ")\n",
    "\n",
    "sunsyn=[]\n",
    "num_sat=3\n",
    "num_pla=3\n",
    "for i in range(num_pla):\n",
    "\n",
    "    h_ref=800e3\n",
    "    viirs = Instrument(\n",
    "        name=\"VIIRS\",\n",
    "        field_of_regard=swath_width_to_field_of_regard(h_ref, 3000e3),\n",
    "\n",
    "        fixed_access_time=True\n",
    "    )\n",
    "\n",
    "    d=SunSynchronousOrbit(name='test',\n",
    "                          type='sso',\n",
    "                          altitude=h_ref,\n",
    "                          equator_crossing_time= '20:00',\n",
    "                          equator_crossing_ascending= True\n",
    "                          )\n",
    "\n",
    "    sunsyn.append(WalkerConstellation(name=f'Sunsynchronous_plane{i}',\n",
    "                            orbit= d.to_tle(),\n",
    "                            instruments=[viirs],\n",
    "                            number_satellites=num_sat,\n",
    "                            number_planes=i+1,\n",
    "                            configuration='star',\n",
    "                                    ).generate_members()\n",
    "                  )\n",
    "\n",
    "c_one=[sats+ sunsyn[0] for sats in constellations]\n",
    "c_two=[sats+ sunsyn[1] for sats in constellations]\n",
    "c_three=[sats+ sunsyn[2] for sats in constellations]\n",
    "\n",
    "total_constellations= c_one+ c_two + c_three # 96 mission architectures\n",
    "\n",
    "\n",
    "s2=[WalkerConstellation(name='Starlink',\n",
    "                       orbit=CircularOrbit(type='circular',\n",
    "                                          altitude=600e3,\n",
    "                                          inclination=53,\n",
    "                                          ).to_tle(),\n",
    "                       instruments=[Instrument(\n",
    "                                   name=\"startlink\",\n",
    "                                   field_of_regard=swath_width_to_field_of_regard(600e3, 50e3), #assumes 50 Km swath\n",
    "                                   fixed_access_time=True\n",
    "                               )],\n",
    "                       number_satellites= 60,\n",
    "                       number_planes=12,\n",
    "                       configuration='star'\n",
    "\n",
    "                       ).generate_members()\n",
    "    ]\n",
    "total_constellations= total_constellations+ s2 \n",
    "\n",
    "small_sunsys=[WalkerConstellation(name=f'sunsy_planes{np}',\n",
    "                       orbit=SunSynchronousOrbit(name='sunsyn',\n",
    "                                             type='sso',\n",
    "                                             altitude=600e3,\n",
    "                                             equator_crossing_time= '20:00',\n",
    "                                             equator_crossing_ascending= True\n",
    "                                             ).to_tle(),\n",
    "                       instruments=[Instrument(\n",
    "                                   name=\"ST_V2\",\n",
    "                                   field_of_regard=swath_width_to_field_of_regard(600e3, 20e3), #assumes 20 Km swath \n",
    "                                   fixed_access_time=True\n",
    "                               )],\n",
    "                       number_satellites= 60,\n",
    "                       number_planes=np,\n",
    "                       configuration='star'\n",
    "\n",
    "                       ).generate_members()\n",
    "              for np in [5, 15, 30]\n",
    "              ]\n",
    "\n",
    "all_cons= total_constellations+small_sunsys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4cbb9-fd4c-4a8d-810c-c766d933affe",
   "metadata": {},
   "source": [
    "Once the 100 mission architectures have been defined, we run a revisit time analysis for each architecture in the list. The following script details the functions we defined to run this analysis. The `run_celery_revisit` function builds a task request that performs revisit time for a mission architecture. This function writes the coverage results in a file called \"trade_results\" with the name of the respective architecture and writes harmonic mean in a file called \"hmean_list.txt\". Writing results of each mission architecture will prevent re-running tasks in the case of network dispruption. Additionally, the function `tradespace_analysis_revisit` builds a list of harmonic mean values provided by the `run_celery_revisit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e3ae8-6f76-4570-9ed1-77c0a180512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tatc.schemas import Satellite, Instrument,Architecture, Point\n",
    "from tatc.generation import generate_fibonacci_lattice_points\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from celery import chain, group\n",
    "import time\n",
    "from tatc_app.coverage_tasks import (run_coverage_analysis_task, \n",
    "                                    merge_feature_collections_task\n",
    "                                    )\n",
    "from geojson_pydantic import FeatureCollection\n",
    "import geopandas as gpd\n",
    "from scipy import stats \n",
    "#from define_architectures_for_trade import all_cons\n",
    "from geojson import dump\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def run_celery_revisit(start:datetime, end: datetime, \n",
    "                       arch: Architecture, points: gpd.GeoDataFrame) -> float:\n",
    "    constellation= arch.satellites\n",
    "    task= chain(\n",
    "        group(\n",
    "            run_coverage_analysis_task.s(\n",
    "                point.model_dump_json(),\n",
    "                [sat.model_dump_json() for sat in constellation],\n",
    "                start.isoformat(),\n",
    "                end.isoformat(),\n",
    "               )\n",
    "            for point in points\n",
    "            ),\n",
    "        merge_feature_collections_task.s(),\n",
    "        )()\n",
    "    finished=False\n",
    "    while finished==False:\n",
    "        time.sleep(1.5)\n",
    "        finished= task.ready()\n",
    "    #print(f\"{arch.name} has been executed successfully\")\n",
    "    res=FeatureCollection.model_validate_json(task.get())\n",
    "    gdf_r= gpd.GeoDataFrame.from_features(res)\n",
    "    gdf_r=gdf_r.dropna()\n",
    "    \n",
    "    re=np.round(stats.hmean(gdf_r.revisit), 2)\n",
    "   \n",
    "    #print('hmean=', re)\n",
    "    with open(f'trade_results/{arch.name}.geojson', 'w') as f:\n",
    "       dump(res, f)\n",
    "    \n",
    "    with open('hmean_list.txt', 'a') as file:\n",
    "        file.write(f'{re}\\n')\n",
    "    return re \n",
    "\n",
    "\n",
    "def tradespace_analysis_revisit(start: datetime,\n",
    "                        end: datetime,\n",
    "                        missions: list[Architecture],\n",
    "                        points: gpd.GeoDataFrame):\n",
    "    results=[run_celery_revisit(start, end, arch, points) for arch in missions]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "start = datetime(\n",
    "    year=2023, \n",
    "    month=9, \n",
    "    day=15, \n",
    "    hour=0, \n",
    "    minute=0, \n",
    "    tzinfo=timezone.utc\n",
    ")\n",
    "end = start + timedelta(days=30)\n",
    "\n",
    "\n",
    "points_df = generate_fibonacci_lattice_points(1000e3)\n",
    "\n",
    "points = points_df.apply(\n",
    "    lambda r: Point(\n",
    "        id=r.point_id, \n",
    "        latitude=r.geometry.y, \n",
    "        longitude=r.geometry.x\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "from tatc.schemas import GroundStation\n",
    "\n",
    "mcmurdo = GroundStation(\n",
    "    name=\"McMurdo\", \n",
    "    latitude=-77.846323, \n",
    "    longitude=166.668235, \n",
    "    elevation=150, \n",
    "    min_elevation_angle=5\n",
    ")\n",
    "svalbard = GroundStation(\n",
    "    name=\"Svalbard\", \n",
    "    latitude=78.229772, \n",
    "    longitude=15.407786, \n",
    "    elevation=450, \n",
    "    min_elevation_angle=5\n",
    ")\n",
    "fairbanks = GroundStation(\n",
    "    name=\"Fairbanks\", \n",
    "    latitude=64.97381, \n",
    "    longitude=-147.50575, \n",
    "    elevation=400, \n",
    "    min_elevation_angle=5\n",
    ")\n",
    "troll = GroundStation(\n",
    "    name=\"Troll\", \n",
    "    latitude=-72.016667, \n",
    "    longitude=2.533333, \n",
    "    elevation=1275, \n",
    "    min_elevation_angle=5\n",
    ")\n",
    "\n",
    "ground_network = [mcmurdo, svalbard, fairbanks, troll]\n",
    "\n",
    "\n",
    "missions= [Architecture(name= f\"mission_{i}\",\n",
    "                       satellites= all_cons[i],\n",
    "                       stations= ground_network\n",
    "                       )\n",
    "           for i in range(len(all_cons))\n",
    "          ]\n",
    "\n",
    "results=tradespace_analysis_revisit(start,\n",
    "                        end,\n",
    "                        missions,\n",
    "                        points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b3664-ae39-4f34-8802-066b23ebc63b",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "This section discusses the results of the tradespace analysis. The graph on the right shows the average sample per point (ASpP) on the x-axis and the harmonic mean in hours on the y-axis. The four outliers shown on the upper left side represent the architectures with 60 satellites. While these constellations have many satellites, their sensor features a small and nadir-pointing swath width, which limits the satellite coverage. On the other hand, the best designs perform low harmonic mean with high ASpP; the best designs are located at the lower right side of the graph. We plot a second graph with only the best designs. Note that these designs comprise 15 satellites. \n",
    "\n",
    "The second graph displays the number of planes vs harmonic mean for all best desings. We observe that designs with fewer planes offer a relatively lower harmonic mean than designs with higher planes in their constellations. Expectedly, designs with a wide field of regard (FOR) perform better than designs with a narrow FOR.\n",
    "\n",
    "<img src='./images/results.png' align='center'/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d64efb-14a3-466d-b208-cd0883cea06a",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This report developed a scalable architecture, which reduces TAT-C's simulation runtime by approximately 70% compared to a single-machine worker network. The architecture utilizes the Python celery library to perform independent tasks asynchronously. We split a big task, such as revisit time analysis for a mission architecture, into small and independent tasks to process in parallel. The small tasks perform revisit time per each target point in the grid because it provides low network latency. \n",
    "\n",
    "Also, we performed a tradespace analysis considering 100 hypothetical architectures. The results show that an architecture with 15 satellites in five orbital planes offers a lower harmonic mean than other architectures with more orbital planes, which increases the cost of a mission. The scalable architecture is an instrumental tool for exploring a wide range of hypothetical mission archictectures that maximize performance at an attainable cost. \n",
    "\n",
    "Ultimately, this scalable framework can support the ASPEN tool by autonomously evaluating the refresh or revisit time and data latency of a wide range of architectures. Given that tatc is an open-source tool, the framework built in this study can be built easily from any computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03869cf4-3dc7-4bb1-a2ea-f1dd4c13fd01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
