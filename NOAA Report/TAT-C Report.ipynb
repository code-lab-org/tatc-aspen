{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518a70ab-1ac3-44df-a05e-f2625865384f",
   "metadata": {},
   "source": [
    "# TAT-C for Scalable Services Report\n",
    "PI: Paul T. Grogan paul.grogan@asu.edu\n",
    "\n",
    "Contributors: Josue Tapia josue.tapia@asu.edu and Suvan Kumar skuma208@asu.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253d428-6304-4e6d-8a86-cfb34a7440f7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This report provides an overview of the Tradespace Analysis Tool for Constellations (TAT-C) architecture for scalable services to support trade space exploration and assesment of hypothetical mission designs autonomously and to interface with the NOAA's ASPEN trade space evaluation tool. The new architecture leverages the Celery python library to distribute and execute tasks in parallel, reducing the simulation runtime per mission assesment.This work has been performed under the project \"OSSE / Trade Space Capability for NOAA's Future Mission Design.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba075e51-d890-480d-8500-b0409f9e8e40",
   "metadata": {},
   "source": [
    "# Background\n",
    "## TAT-C Capabilities\n",
    "The Tradespace Analysis Tool for Constellations (TAT-C) is an open-source Python software package for early-stage mission modeling, simulation, and analysis for Earth-observing satellite constellations. It was developed with support from the NASA Advanced Information Systems Technology (AIST) program grants NNX17AE06G, 80NSSC17K0586, 80NSSC20K1118, and 80NSSC21K1515. This project uses TAT-C version 3 which is the third major revision to the tool.\n",
    "\n",
    "TAT-C simulates the orbital motion and observability conditions of satellite-based instruments and produces data such as orbit track, ground track (projected sensor area), and observation records. Analysis methods compute key mission performance metrics such as revisit time (time between subsequent observations of a fixed point) and data latency (time from observation of a fixed point until the first available downlink opportunity) to support trade studies.\n",
    "\n",
    "The overall objective of this project is to use TAT-C as a pre-processor for the Advanced Systems Performance Evaluation tool for NOAA (ASPEN) Sensor Constellation/Performance (SCP) table. SCP columns that can be informed by TAT-C analysis include (descriptions from ASPEN-91 definition tables):\n",
    "\n",
    "*  Temporal Refresh: \"Time between obsevations at a location, i.e., time to obseve the geographic coverage region D.\"\n",
    "*  Data Latency: \"Time from 'image taken' to full relay of data to a ground station.\" (Note: TAT-C does not consider processing time as a part of data latency; in other words, an additional factor must be added to the TAT-C results.)\n",
    "  \n",
    "TAT-C models instrument observability constraints rather geophysical variables. Instruments selected for this report consist of infrared and microwave sounders and visual/infrared imagers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747303b7-f23c-47f1-9105-e19a237d247d",
   "metadata": {},
   "source": [
    "# TAT-C Configuration\n",
    "This report uses TAT-C version 3.1.3 which is currently in development on the main branch of GitHub. Technical documentation is available at ReadTheDocs.\n",
    "\n",
    "To install TAT-C, clone the repository:\n",
    "\n",
    "    git clone https://github.com/code-lab-org/tatc\n",
    "and install the dependencies into a new environment (tatc_env) using conda:\n",
    "\n",
    "    conda env create -f environment.yml\n",
    "(note: dependency resolution can take upwards of 10 minutes). Activate the new environment when complete:\n",
    "\n",
    "    conda activate tatc_env\n",
    "and register the TAT-C library in \"editable\" mode (enables source changes, if desired):\n",
    "\n",
    "    pip install -e .\n",
    "This report also requires the following additional dependencies for parallel processing and interactive features of a Jupyter notebook:\n",
    "\n",
    "    conda install ipython joblib pandarallel -c conda-forge\n",
    "and a world country-level shapefile `ne_110m_admin_0_countries.zip` available from NaturalEarth (Select \"Download countries\" and save the .zip file in the same directory as this notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f19d8-15be-4647-a460-b27d67b53e39",
   "metadata": {},
   "source": [
    "#  Simulation Runtime Limitation\n",
    "The TAT-C is a long runtime simulation analysis tool due to computing-intense tasks. As a result, TAT-C can be used for narrow trade space analysis, which evaluate the performance of a few misison architectures. This limitiation hinders mission designs that could maximize system performance while minimizing costs. \n",
    "\n",
    "This leads to the need for scalable approches that reduce the TAT-C's simulation runtime. The following section describes a scalable architecture that relies on the python Celery library, which computes tasks in parallel and asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e6b7cc-c08f-4588-8dc6-aa1d8fbd8046",
   "metadata": {},
   "source": [
    "# Scalable Architecture\n",
    "\n",
    "The image bellow represents the scalabe architectures developed in this report. There are three main components in the architecture: the TAT-C application, the backend and message broker, and the workers machine. The celery framework supports a message Rabbit MQ message broker that handles tasks through a task queue and that distributes tasks to worker machines, which execute the tasks. As workers complete tasks, they store the results in a database, the Redis database. Once all tasks are complete, TAT-C request the results to the Redis database and aggregates the results to compute coverage analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a98292-7fe1-43c4-a42d-54a2541372dd",
   "metadata": {},
   "source": [
    "<img src='./images/Scalable_Architecture.png' align='center'/>\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31ab8eb4-879f-46e7-a13d-2ac88fc97e1d",
   "metadata": {},
   "source": [
    "## TAT-C Application\n",
    "\n",
    "This subsection shows how the TAT-C application breaks down a big task, such as the refresh analysis for a mission architecture, into small and independent tasks that can be executed in parallel. Additionally, the subsection describes the Celery workflows used in the architecture.  \n",
    "\n",
    "### Celery Workflows\n",
    "\n",
    "Celery process and handles data flows as shown in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76eae29-0ee6-41fb-9196-ab12be9f45c2",
   "metadata": {},
   "source": [
    "<img src='./images/celery_workflows.png' width='600' align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df365e2-7c7e-40e7-96b4-4f107b15df87",
   "metadata": {},
   "source": [
    "* The chain workflow executes tasks in sequence, one after another. The results of each tasks are passed to the following task as the first argument. The output is a result value processed by the last task.\n",
    "* The group workflow executes a set of tasks in parallel. The output is a list of results of each task.\n",
    "* The chord workflow executes a task after a set of tasks computed in parallel. The results of the of the group tasks are passed to the last task as the first argument.The output is a result processed by the last task.\n",
    "\n",
    "Note that the data trasnfered from one task to another needs to be serialized. Since tatc outputs geodataframes with coverage statistics, we need to serialize the geodataframes to pass results from one taks to the next ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166ac43-4fc2-4cdf-9699-4c0b20f13d49",
   "metadata": {},
   "source": [
    "### Grouping Small Tasks for Scalable Services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90006e5-67f3-40a7-a0e0-685c20da4927",
   "metadata": {},
   "source": [
    "There are multiple ways to structure functions in tatc to provide coverage or data latency statistics using Celery's workflows. We determined that the following workflows offers a lower network latency. The diagram below shows the workflow implemented in this project. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85870d85-7a1f-49f9-878a-4fa5b4279f34",
   "metadata": {},
   "source": [
    "<img src='./images/run_coverage_analysis.jpg' width='600' align='center'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dddf2d9-d1c9-42a9-ae4b-2c530e575037",
   "metadata": {},
   "source": [
    "The `run_coverage_analysis_task` performs coverage analysis for a constellation over one target point in the grid. The result of the group workflow is a list of coverage analysis for all points in the grid. The results from the group workflows are passed to the `merge_feature_collection` task, which merges a list of geodataframes into one geoataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ffe15-fe39-4a25-b8da-a11e7dfb1543",
   "metadata": {},
   "source": [
    "##  Message Broker and Backend\n",
    "\n",
    "This project utilzes the Rabbit MQ message broker and backend hosted in Amazon Web Servicies (AWS).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86dd23a-8e95-4cb4-b41a-9f900b542fb1",
   "metadata": {},
   "source": [
    "## IP Data Transfer\n",
    "\n",
    "The communication between message broker, backend, tatc appication, and machine workers is done by using the https protocol. The protocol encrypts the messages. The advantage of using the https protocol in the network is that it can connect workers that are distributed globally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba7884-023f-43f0-9167-fdacd8076be5",
   "metadata": {},
   "source": [
    "## Machine Workers\n",
    "We built a docker image that builds a worker machine container. This container carries all dependencies needed to run a coverage analys using tatc. The image is publicly available in Docker Hub (josuetapia/parallelworker:latest). Alternatively, the image file is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619396d1-209c-4836-b6d6-de81cec4f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block defines the TAT-C runtime container using the appropriate\n",
    "# base Python environment.\n",
    "\n",
    "FROM python:3.10 AS tatc_runtime\n",
    "\n",
    "WORKDIR /var/tatc\n",
    "COPY pyproject.toml ./\n",
    "COPY src src\n",
    "RUN python -m pip install . --no-cache-dir\n",
    "\n",
    "# This block defines the TAT-C worker container. Using the TAT-C runtime\n",
    "# container, it installs and starts the worker application.\n",
    "\n",
    "FROM tatc_runtime AS tatc_worker\n",
    "\n",
    "WORKDIR /var/tatc\n",
    "RUN python -m pip install .[app] --no-cache-dir\n",
    "\n",
    "COPY tatc_app tatc_app\n",
    "COPY resources resources\n",
    "\n",
    "ENV TATC_BROKER=amqp://tatc:tatc07030@tatc-test.code-lab.org:5671//\n",
    "ENV TATC_BACKEND=redis://tatc07030@tatc-test.code-lab.org:6379/\n",
    "\n",
    "CMD [\"celery\", \"-A\", \"tatc_app.aws_worker\", \"worker\", \"--uid=nobody\", \"--gid=nogroup\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d7e6a-ac0e-4b27-ad1a-3b4942c36370",
   "metadata": {},
   "source": [
    "The docker image file is located in the same directory as the tatc_app file, which contains the celery application initializer (`aws_worker` file) as well as coverage tasks. The celery application initilizer is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d782c5ad-e5a3-4323-8627-43564a203248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from celery import Celery\n",
    "from skyfield.api import load\n",
    "import ssl\n",
    "\n",
    "app=Celery('tatc_app',\n",
    "           broker='amqps://tatc:tatc07030@tatc-test.code-lab.org:5671//',\n",
    "           broker_use_ssl= {\n",
    "               \"keyfile\": None,\n",
    "               \"certfile\":None,\n",
    "               \"ca_certs\": None,\n",
    "               \"cert_reqs\": ssl.CERT_NONE,\n",
    "               },\n",
    "           backend='rediss://:tatc07030@tatc-test.code-lab.org:6379/',\n",
    "           redis_backend_use_ssl={\n",
    "               \"ssl_keyfile\": None,\n",
    "               \"ssl_certfile\": None,\n",
    "               \"ssl_ca_certs\": None,\n",
    "               \"ssl_cert_reqs\": ssl.CERT_NONE,\n",
    "               },\n",
    "           include=['tatc_app.latency_tasks', 'tatc_app.coverage_tasks']\n",
    "    )\n",
    "\n",
    "load(\"de421.bsp\")\n",
    "if __name__=='__main__':\n",
    "    app.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb0a88-6c4e-4fb6-b4b9-0e9a72d9aa60",
   "metadata": {},
   "source": [
    "The following script shows the underlying tatc functions that support the `run_coverage_analysis_task` and the `merge_feature_collection_task` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91641ec-e5a6-4402-b014-fd2778f987fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import geopandas as gpd\n",
    "from geojson_pydantic import FeatureCollection\n",
    "import json\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "from tatc.schemas.instrument import Instrument\n",
    "from tatc.schemas.point import Point\n",
    "from tatc.schemas.satellite import Satellite\n",
    "from tatc.analysis.coverage import (\n",
    "    collect_multi_observations,\n",
    "    aggregate_observations,\n",
    "    reduce_observations,\n",
    "    grid_observations,\n",
    ")\n",
    "\n",
    "#from .schemas import CoverageAnalysisResult\n",
    "from .aws_worker import app\n",
    "@app.task\n",
    "def run_coverage_analysis_task(\n",
    "    point: str, satellites: list, start: str, end: str\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Task to run coverage analysis.\n",
    "\n",
    "    Args:\n",
    "        point (str): JSON serialized :class:`tatc.schemas.Point` object.\n",
    "        satellites (list): List of JSON serialized :class:`tatc.schemas.Satellite` objects.\n",
    "        start (str): ISO 8601 serialized start time.\n",
    "        end (str): ISO 8601 serialized end time.\n",
    "\n",
    "    Returns:\n",
    "        str: GeoJSON serialized `FeatureCollection` containing coverage analysis.\n",
    "    \"\"\"\n",
    "    # call analysis function, parsing the serialized arguments\n",
    "    results = reduce_observations(\n",
    "        aggregate_observations(\n",
    "            collect_multi_observations(\n",
    "                Point.parse_raw(point),\n",
    "                [Satellite.parse_raw(satellite) for satellite in satellites],\n",
    "                datetime.fromisoformat(start),\n",
    "                datetime.fromisoformat(end),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    # re-serialize constituent data\n",
    "    results[\"access\"] = results[\"access\"].apply(lambda t: t/timedelta(hours=1))\n",
    "    results[\"revisit\"] = results[\"revisit\"].apply(lambda t: t/timedelta(hours=1))\n",
    "    return results.to_json(show_bbox=False, drop_id=True)\n",
    "\n",
    "@app.task\n",
    "def merge_feature_collections_task(collections: list) -> str:\n",
    "    \"\"\"\n",
    "    Task to merge a list of feature collections into a single feature collection.\n",
    "\n",
    "    Args:\n",
    "        collections (list): GeoJSON serialized list of feature collections.\n",
    "\n",
    "    Results:\n",
    "        str: GeoJSON serialized feature collection.\n",
    "    \"\"\"\n",
    "    return FeatureCollection(\n",
    "        type=\"FeatureCollection\",\n",
    "        features=list(\n",
    "            chain(\n",
    "                *list(\n",
    "                    FeatureCollection.model_validate_json(collection).features\n",
    "                    for collection in collections\n",
    "                )\n",
    "            )\n",
    "        ),\n",
    "    ).model_dump_json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
